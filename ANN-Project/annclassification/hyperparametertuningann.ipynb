{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Determining the optimal number of hidden layers and neurons for an Artificial Neural Network (ANN) \n",
    "This can be challenging and often requires experimentation. However, there are some guidelines and methods that can help you in making an informed decision:\n",
    "\n",
    "- Start Simple: Begin with a simple architecture and gradually increase complexity if needed.\n",
    "- Grid Search/Random Search: Use grid search or random search to try different architectures.\n",
    "- Cross-Validation: Use cross-validation to evaluate the performance of different architectures.\n",
    "- Heuristics and Rules of Thumb: Some heuristics and empirical rules can provide starting points, such as:\n",
    "  -    The number of neurons in the hidden layer should be between the size of the input layer and the size of the output layer.\n",
    "  -  A common practice is to start with 1-2 hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('Churn_Modelling.csv')\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "label_encoder_gender = LabelEncoder()\n",
    "data['Gender'] = label_encoder_gender.fit_transform(data['Gender'])\n",
    "\n",
    "onehot_encoder_geo = OneHotEncoder(handle_unknown='ignore')\n",
    "geo_encoded = onehot_encoder_geo.fit_transform(data[['Geography']]).toarray()\n",
    "geo_encoded_df = pd.DataFrame(geo_encoded, columns=onehot_encoder_geo.get_feature_names_out(['Geography']))\n",
    "\n",
    "data = pd.concat([data.drop('Geography', axis=1), geo_encoded_df], axis=1)\n",
    "\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Save encoders and scaler for later use\n",
    "with open('label_encoder_gender.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder_gender, file)\n",
    "\n",
    "with open('onehot_encoder_geo.pkl', 'wb') as file:\n",
    "    pickle.dump(onehot_encoder_geo, file)\n",
    "\n",
    "with open('scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define a function to create the model and try different parameters(KerasClassifier)\n",
    "\n",
    "def create_model(neurons=32,layers=1):\n",
    "    model=Sequential()\n",
    "    model.add(Dense(neurons,activation='relu',input_shape=(X_train.shape[1],)))\n",
    "\n",
    "    for _ in range(layers-1):\n",
    "        model.add(Dense(neurons,activation='relu'))\n",
    "\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(optimizer='adam',loss=\"binary_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a Keras classifier\n",
    "model=KerasClassifier(layers=1,neurons=32,build_fn=create_model,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the grid search parameters\n",
    "param_grid = {\n",
    "    'neurons': [16, 32, 64, 128],\n",
    "    'layers': [1, 2],\n",
    "    'epochs': [50, 100]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: scikit-learn 1.4.2\n",
      "Uninstalling scikit-learn-1.4.2:\n",
      "  Successfully uninstalled scikit-learn-1.4.2\n",
      "Collecting scikit-learn==1.3.1\n",
      "  Using cached scikit_learn-1.3.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/pankajnargesh/workspace/python/venv/lib/python3.12/site-packages (from scikit-learn==1.3.1) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/pankajnargesh/workspace/python/venv/lib/python3.12/site-packages (from scikit-learn==1.3.1) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/pankajnargesh/workspace/python/venv/lib/python3.12/site-packages (from scikit-learn==1.3.1) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/pankajnargesh/workspace/python/venv/lib/python3.12/site-packages (from scikit-learn==1.3.1) (3.5.0)\n",
      "Using cached scikit_learn-1.3.1-cp312-cp312-macosx_12_0_arm64.whl (9.3 MB)\n",
      "Installing collected packages: scikit-learn\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "scikeras 0.13.0 requires scikit-learn>=1.4.2, but you have scikit-learn 1.3.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed scikit-learn-1.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall -y scikit-learn\n",
    "!pip install scikit-learn==1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pankajnargesh/workspace/python/venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:354: FutureWarning: The KerasClassifier or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'super' object has no attribute '__sklearn_tags__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Perform grid search\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m grid \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodel, param_grid\u001b[39m=\u001b[39mparam_grid, n_jobs\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, cv\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,verbose\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m grid_result \u001b[39m=\u001b[39m grid\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb#W6sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# Print the best parameters\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pankajnargesh/workspace/python/ANN-Project/annclassification/hyperparametertuningann.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mBest: \u001b[39m\u001b[39m%f\u001b[39;00m\u001b[39m using \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (grid_result\u001b[39m.\u001b[39mbest_score_, grid_result\u001b[39m.\u001b[39mbest_params_))\n",
      "File \u001b[0;32m~/workspace/python/venv/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/workspace/python/venv/lib/python3.12/site-packages/sklearn/model_selection/_search.py:932\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    928\u001b[0m params \u001b[39m=\u001b[39m _check_method_params(X, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m    930\u001b[0m routed_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_routed_params_for_fit(params)\n\u001b[0;32m--> 932\u001b[0m cv_orig \u001b[39m=\u001b[39m check_cv(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcv, y, classifier\u001b[39m=\u001b[39mis_classifier(estimator))\n\u001b[1;32m    933\u001b[0m n_splits \u001b[39m=\u001b[39m cv_orig\u001b[39m.\u001b[39mget_n_splits(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mrouted_params\u001b[39m.\u001b[39msplitter\u001b[39m.\u001b[39msplit)\n\u001b[1;32m    935\u001b[0m base_estimator \u001b[39m=\u001b[39m clone(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mestimator)\n",
      "File \u001b[0;32m~/workspace/python/venv/lib/python3.12/site-packages/sklearn/base.py:1237\u001b[0m, in \u001b[0;36mis_classifier\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m   1230\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1231\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpassing a class to \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mprint\u001b[39m(inspect\u001b[39m.\u001b[39mstack()[\u001b[39m0\u001b[39m][\u001b[39m3\u001b[39m])\u001b[39m}\u001b[39;00m\u001b[39m is deprecated and \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1232\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwill be removed in 1.8. Use an instance of the class instead.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1233\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1234\u001b[0m     )\n\u001b[1;32m   1235\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39m_estimator_type\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1237\u001b[0m \u001b[39mreturn\u001b[39;00m get_tags(estimator)\u001b[39m.\u001b[39mestimator_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/workspace/python/venv/lib/python3.12/site-packages/sklearn/utils/_tags.py:405\u001b[0m, in \u001b[0;36mget_tags\u001b[0;34m(estimator)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mfor\u001b[39;00m klass \u001b[39min\u001b[39;00m \u001b[39mreversed\u001b[39m(\u001b[39mtype\u001b[39m(estimator)\u001b[39m.\u001b[39mmro()):\n\u001b[1;32m    404\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m__sklearn_tags__\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(klass):\n\u001b[0;32m--> 405\u001b[0m         sklearn_tags_provider[klass] \u001b[39m=\u001b[39m klass\u001b[39m.\u001b[39;49m__sklearn_tags__(estimator)  \u001b[39m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         class_order\u001b[39m.\u001b[39mappend(klass)\n\u001b[1;32m    407\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m_more_tags\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mvars\u001b[39m(klass):\n",
      "File \u001b[0;32m~/workspace/python/venv/lib/python3.12/site-packages/sklearn/base.py:540\u001b[0m, in \u001b[0;36mClassifierMixin.__sklearn_tags__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__sklearn_tags__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 540\u001b[0m     tags \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m__sklearn_tags__()\n\u001b[1;32m    541\u001b[0m     tags\u001b[39m.\u001b[39mestimator_type \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassifier\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    542\u001b[0m     tags\u001b[39m.\u001b[39mclassifier_tags \u001b[39m=\u001b[39m ClassifierTags()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'super' object has no attribute '__sklearn_tags__'"
     ]
    }
   ],
   "source": [
    "# Perform grid search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3,verbose=1)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
